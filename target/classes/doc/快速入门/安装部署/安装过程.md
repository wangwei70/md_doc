title: 安装过程 updateAt: 2023-09-28 10:00:00 ---
## 创建用户

使用root用户，创建用户：
	
`useradd -d /data/antcdc -m antcdc`

`passwd antcdc`

## 安装程序包
AntCDC分为单机和高可用两种部署方式。

### 单机部署启动
执行`sh install.sh`

### 集群部署启动

下面以一台主机为例，如果需要每台主机进行调整的过程，会做特殊说明。

- 步骤1 使用antcdc用户，将程序包安装在用户根目录下：

	`tar -zxvf AntCDC-release-2.0.centos7.x86_64.tar.gz`

- 步骤2 安装jdk：

	`cd ~/java11`

	`tar -zxvf jdk-11.0.11\_linux-x64\_bin.tar.gz`

	`java –version`进行查看

- 步骤3 修改环境变量，并使之生效：

	`vi ~/.bashrc`

	如需调整，修改这个环境变量：

	`export JAVA\_HOME=/data/antcdc/java11/jdk-11.0.11`

	`export PATH=${PATH}:${JAVA\_HOME}/bin`

	保存退出。

	`source ~/.bashrc`

- 步骤4 从配置样例实例化一份配置文件出来：

	`cd ~/rel/antcdc`

	`cp -r config.example config`

- 步骤5 修改zookeeper的配置文件：

	`vi ~/rel/antcdc/config/zookeeper.properties`

	按照实际情况进行配置：

	`tickTime=2000`

	`initLimit=10`

	`syncLimit=5`

	`dataDir=/tmp/zookeeper`【根据要求配置】

	`server.1=10.21.10.1:3188:3288`

	`server.2=10.21.10.2:3188:3288`

	`server.3=10.21.10.3:3188:3288`

	增加zookeeper的myid文件：

	`mkdir /tmp/zookeeper`【参考dataDir的配置】

	`echo 1 > /tmp/zookeeper/myid `【每台主机根据配置文件中的id加入myid文件，必须与配置文件中"server"后面的序号一一对应】
	
- 步骤6 启动zookeeper

	`cd ~/rel/antcdc`

	`./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties`

- 步骤7 修改kafka的配置文件：

	`vi ~/rel/antcdc/config/server.properties`

	按照实际情况进行配置：

	`broker.id=0`【每台主机使用不同的id】

	`listeners=PLAINTEXT://:9092`

	`advertised.listeners=PLAINTEXT://10.21.10.146:9092`

	`log.dirs=kafka-logs`【根据要求配置】

	`num.partitions=6`

	`zookeeper.connect=10.21.10.146:2181,10.21.10.148:2181,10.21.10.149:2181`【对应步骤6启动的所有Zookeeper服务节点】

	`offsets.topic.replication.factor=3`

	`replication.factor=3`

	`transaction.state.log.replication.factor=3`

	`transaction.state.log.min.isr=3`

- 步骤8 启动kafka

	`cd ~/rel/antcdc`

	`./bin/kafka-server-start.sh -daemon config/server.properties`
	
- 步骤9 启动kafkasql【非必启中间件，只需选择集群中的某一台主机启动一个服务即可】

	`cd ~/rel/antcdc/kafkasql`

	`nohup $JAVA\_HOME/bin/java -Dregistry.kafka.common.bootstrap.servers=192.168.10.146:9092,192.168.10.148:9092,192.168.10.149:9092 -Dquarkus.http.port=8080 -jar apicurio-registry-storage-kafkasql-2.2.5.Final-runner.jar \>/dev/null&` 【#对应步骤8启动的所有kafka服务节点】


- 步骤10 修改kafka connect的配置文件

	`vi ~/rel/antcdc/config/connect-distributed.properties`

	按照实际情况进行配置：

	`bootstrap.servers=10.21.10.146:9092,10.21.10.148:9092,10.21.10.149:9092` 【对应步骤8的所有kafka服务节点】

	`listeners=HTTP://10.21.10.146:8083`

	`offset.storage.replication.factor=3`

	`config.storage.replication.factor=3`

	`status.storage.replication.factor=3`

	`rest.extension.classes=com.ai.dbsync.metric.ext.DbSyncMetricRestExtension`

	`plugin.path=dbsync-lib`
	
- 步骤11 启动kafka connect

	`cd ~/rel/antcdc`

	`./bin/connect-distributed.sh -daemon config/connect-distributed.properties`

- 步骤12 修改管理工具的配置文件

	`vi ~/rel/antcdc/config/application.properties`

	按照实际情况进行配置：

	`logging.level.root=error`

	`kafka.connector.url=HTTP://192.168.10.146:8083,HTTP://192.168.10.148:8083,HTTP://192.168.10.149:8083`【对应步骤11启动的所有kafka connect服务节点】

	`kafka.bootstrap.servers=192.168.10.146:9092,192.168.10.148:9092,192.168.10.149:9092`【对应步骤8启动的所有kafka服务节点】

	`spring.datasource.web.jdbc-url = jdbc:h2:file:~/.h2/webdb;AUTO_SERVER=TRUE`

	`spring.datasource.web.username = xxx`

	`spring.datasource.web.password = xxx`

	`spring.flyway.locations=classpath:db/h2/migration`

	`server.port = 8000`

	`spring.datasource.web.max-active=20`

	`spring.datasource.web.max-idle=8`

	`spring.datasource.web.min-idle=8`

	`spring.datasource.web.initial-size=10`

	`log.mining.thread.num=4`

	`schema.register.url=http://192.168.10.149:8080/apis/registry/v2` 【对应步骤9启动的kafkasql服务节点】

	`es.statistics.interval=5000`

	`flow.statistics.interval=30000`

- 步骤13 调整JVM内存分配

	`vi ~/rel/antcdc/config/mem-env`

	对于需要修改默认内存分配大小的，解除注释标志"#"，并按照实际情况进行配置：

	`# ZOOKEEPER_JVM_HEAP="-Xms1G -Xmx1G"`

	`# KAFKA_JVM_HEAP="-Xms1G -Xmx1G"`

	`# CONNECTOR_JVM_HEAP="-Xms1G -Xmx1G"`

	`# WEB_HEAP_OPTS="-Xms1G -Xmx1G"`